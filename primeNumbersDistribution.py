# -*- coding: utf-8 -*-
"""primeNumbersDistribution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hiBg7hLClOtAwb66UpPGUQcUA7I2NP3S

# Prime numbers distribution prediction
This is a project for creating an algorithm using a Q-Learning model for predicting the distribution of prime numbers using most simple operations as possible.

## Incipit
The entire project is based on a simple probability formula:
$notPrimePredictProb = (\frac{1}{n}*(1-notPrimePredictProb))+notPrimePredictProb$

The concept is: you can obtain the statistic prediction of not prime numbers and, by consequence, of prime numbers updating this formula for each prime number. This probability is valid until the next prime number found, so the intent of this project is finding the right algorithm which can use this simple concept for forecast with more precision as possible the prime numbers distribution from 2 to *n*.

Were tested many combinations of algorithms which, using this base formula, can obtain a pretty plausible probability distribution, although not able to predict the right prime numbers in the long term of the cycles.

These promising results led me to work to this Tensorflow-based Q-Learning model which aims to generate the algorithm able to have the best result in the calc of the distribution of prime numbers.

For simplicity and performance rapidity, the project could begin to evaluate numbers from 2 to 10.000, maybe adding a zero per advancement.

## Collaborators
Ideated by Riccardo Cecchini \<rcecchini.ds@gmail.com>

# Base code requirements

Imports:
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as img
from random import sample
from keras import backend as K

from keras.models import Sequential, Model
from keras.layers import Dense, Flatten, Input, Lambda, BatchNormalization, Reshape, GRU, Conv2D, MaxPooling2D, LSTM
from keras.layers import Activation, Concatenate, AveragePooling2D, GlobalAveragePooling2D, TimeDistributed
from keras.optimizers import Adam

import tensorflow as tf

import random
import math

import json

import psutil
import gc

"""## Costum classes"""

myFloat = np.double
if hasattr(np, 'float128'):
    myFloat = np.float128

"""First, calculate prime numbers up to `upTo`, beginning from 2."""

def is_prime(num):
  if num < 2:
    return False
  for i in range(2, int(num ** 0.5) + 1):
    if num % i == 0:
      return False
  return True

upTo = 10000 # 10.000

numIsPrime = []

prime_numbers = []
count = 0
num = 2

while num <= upTo:
  if is_prime(num):
    prime_numbers.append(num)
    numIsPrime.append(True)
  else:
    numIsPrime.append(False)

  num += 1

print("First "+ str(upTo) +" numbers calculated")

"""Then calculate distribution"""

distribution = []
numPrimes = 0
nextPrime = prime_numbers[numPrimes]

n = 2
while n <= upTo:
  if nextPrime == n:
    numPrimes += 1
    if len(prime_numbers) > numPrimes:
      nextPrime = prime_numbers[numPrimes]
    else:
      nextPrime += upTo

  distribution.append(numPrimes)
  n += 1

print("Distribution calculated (",len(distribution),")")

"""# Q-Learning library

Forking code from https://github.com/farizrahman4u/qlearning4k
"""

batch_size = 30

class Agent:

  def __init__(self, model, memory=None, nb_frames=None):
    self.input_shape = model.input_shape[1:]
    print("input_shape: ", self.input_shape)

    self.output_shape = model.layers[-1].output_shape[1:]
    print("output_shape: ", self.output_shape)

    self.fileTraining = 'lastTraining.json'

    self.fileWeights = 'weights.dat'
    if(os.path.exists(self.fileWeights)):
      model.load_weights(self.fileWeights)

    self.model = model

  def get_game_data(self, game):
    frame = game.get_frame()
    return frame

  def saveJson(self, file, var):
    f = open(file, "w")
    f.write(json.dumps(var))
    f.close()

  def readJson(self, file):
    if(os.path.exists(file)):
      f = open(file, "r")
      return json.loads(f.read())
    return None

  def predictOptions(self, game):
    reqs = []
    for o in range(0, game.optionsLen):
      game.selOption = o
      frame = game.get_frame()
      reqs.append(frame)

    reqs = np.array(reqs)
    prediction = model.predict(np.array(reqs))

    res = []
    for p in prediction:
      res.append(p[0])

    return res

  def checkRamUsage(self):
    usedRam = psutil.virtual_memory()[2] # in %
    return usedRam > 70

  def train(self, game, nb_epoch=2000, gamma=0.9, epsilon=[1., .1], epsilon_rate=0.75, observe=0, checkpoint=10, weighedScore = True):

    if type(epsilon)  in {tuple, list}:
      delta =  ((epsilon[0] - epsilon[1]) / (nb_epoch * epsilon_rate))
      final_epsilon = epsilon[1]
      epsilon = epsilon[0]
    else:
      final_epsilon = epsilon

    model = self.model
    nb_actions = model.layers[-1].output_shape[0]
    win_count = 0

    observeModel = False
    totEpochs = nb_epoch
    minEpochsControl = totEpochs / 10
    limitTrainingCount = 99999

    epoch = 0

    lastTrain = self.readJson(self.fileTraining)
    if lastTrain != None:
      delta = lastTrain['delta']
      epsilon = lastTrain['epsilon']
      final_epsilon = lastTrain['final_epsilon']
      epoch = lastTrain['epoch']
      nb_epoch = lastTrain['nb_epoch']
      observeModel = lastTrain['observeModel']
      limitTrainingCount = lastTrain['limitTrainingCount']

    while epoch < nb_epoch:
      epoch += 1

      limitTrainingCount *= 1.1

      ### Training section
      views = []
      targets = []

      def trainView(view=None, target=None):
        debugDisableTraining = False
        if debugDisableTraining:
          return

        nonlocal limitTrainingCount
        nonlocal loss
        nonlocal cycles
        nonlocal views
        nonlocal targets

        execTrain = False
        if view is not None:
          views.append(view)
          targets.append(target)
        else:
          execTrain = len(views) > 0

        execTrain = execTrain or len(views) >= limitTrainingCount

        if execTrain:
          print("Training ", len(views), " elements... ", end="")
          train = model.train_on_batch(np.array(views), np.array(targets))
          print("Loss: ", train)
          loss += float(train)
          cycles += 1

          if self.checkRamUsage():
            limitTrainingCount = len(views) * 0.9
            if limitTrainingCount < 1:
              limitTrainingCount = 1

          views.clear()
          targets.clear()
          K.clear_session()  # try to reduce RAM usage
      ### End training section

      loss = 0.
      accuracy = 0.

      game.reset()

      lastCalculatedLine = 0

      linesScores = [0] * (game.num_lines+1)
      isolatedHashScores = {}

      def getArrHash(arr):
        return hash(arr.tobytes())

      def checkViewScore(view, score):
        h = getArrHash(view)
        if h in isolatedHashScores:
          s = isolatedHashScores[h]

          if s < score:
            isolatedHashScores[h] = score
            return True
          else:
            return False
        else:
          isolatedHashScores[h] = score
          return True


      cycles = 0
      game_over = False
      while not game_over:

        options = game.optionsLen
        if np.random.random() < epsilon or epoch < observe:
          a = int(np.random.randint(options))
        else:
          p = self.predictOptions(game)
          a = int(np.argmax(p))

        game.goDown(a)

        game.goRight() # next parameter

        if game.inNewLine:
          score = game.get_score()

          if game.lastCalculatedScoreLine != lastCalculatedLine:
            lastCalculatedLine = game.lastCalculatedScoreLine

            # Train only the working algorithm
            isolatedInstructions = game.curWinnerInstructions

            scoreWeight = score
            if weighedScore:
              scoreWeight = pow(scoreWeight, 1/len(isolatedInstructions))

            for i in range(0, game.countInstructionsElements(isolatedInstructions)):
              view = game.get_state(i+1, isolatedInstructions)
              if checkViewScore(view, scoreWeight):
                trainView(view, scoreWeight)

            trainView() # flush

            # Save working lines max score
            for i in game.workingLines:
              if linesScores[i] < scoreWeight:
                linesScores[i] = scoreWeight

          game_over = game.is_over()

      # Train the best scores of the total script
      totElements = 0
      for i in range(0, len(game.instructions)):
        instr = game.instructions[i]
        instrLen = len(instr)

        if linesScores[i] > 0:
          for u in range(totElements, totElements + instrLen):
            view = game.get_state(u + 1)
            trainView(view, linesScores[i])

        totElements += instrLen

      trainView() # flush remaining views to train

      gc.collect()

      if checkpoint and ((epoch + 1 - observe) % checkpoint == 0 or epoch >= nb_epoch):
        model.save_weights(self.fileWeights)

        save = {
            'delta': delta,
            'epsilon': epsilon,
            'final_epsilon': final_epsilon,
            'epoch': epoch,
            'nb_epoch': nb_epoch,
            'observeModel': observeModel,
            'limitTrainingCount': limitTrainingCount
        }
        self.saveJson(self.fileTraining, save)

      if game.is_won():
        win_count += 1

      if epsilon > final_epsilon and epoch >= observe:
        epsilon -= delta

        if not observeModel and epsilon < delta:
          if (nb_epoch - epoch) < minEpochsControl:
            nb_epoch = minEpochsControl
            epoch = 0
          observeModel = True

      loss /= cycles
      #loss /= upTo
      accuracy /= cycles

      print("=========================================")
      print("Epoch {:03d}/{:03d} | Loss {:.4f} | Epsilon {:.2f} | Win count {}".format(epoch + 1, nb_epoch, loss, epsilon, win_count))
      print("=========================================")

  def play(self, game, nb_epoch=10, epsilon=0., visualize=False):
    model = self.model
    win_count = 0

    for epoch in range(nb_epoch):
      game.reset()
      self.clear_frames()
      S = self.get_game_data(game)

      game_over = False
      while not game_over:
        if np.random.rand() < epsilon:
          print("random")
          action = int(np.random.randint(0, game.nb_actions))
        else:
          q = model.predict(np.array([S]))
          q = q[0]

          possible_actions = game.get_possible_actions()
          q = [q[i] for i in possible_actions]
          action = possible_actions[np.argmax(q)]

        game.play(action)
        S = self.get_game_data(game)

        game_over = game.is_over()

      if game.is_won():
        win_count += 1

    print("Accuracy {} %".format(100. * win_count / nb_epoch))

    if visualize and False: #todo: handle this possibility on colab
      if 'images' not in os.listdir('.'):
        os.mkdir('images')
      for i in range(len(frames)):
        plt.imshow(frames[i], interpolation='none')
        plt.savefig("images/" + game.name + str(i) + ".png")

###
### Memory
###
class Memory:

    def __init__(self):
        pass

    def remember(self, S, a, r, S_prime, game_over):
        pass

    def get_batch(self, model, batch_size):
        pass


class ExperienceReplay(Memory):

    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.memory = []
        self.orderedMemory = []
        self._memory_size = batch_size

    def remember(self, s, a, r, s_prime, game_over):
        self.orig_input_shape = s.shape

        # Remove superfluous actions
        if len(self.memory) > 0:
          prev = len(self.orderedMemory)-1
          prevA = self.orderedMemory[prev]
          if prevA == 0: # it's action "down"
            self.memory.pop(prev)
            self.orderedMemory.pop(prev)

        concat = np.concatenate([s.flatten(), np.array(a).flatten(), np.array(r).flatten(), s_prime.flatten(), 1 * np.array(game_over).flatten()])
        self.memory.append(concat)
        self.orderedMemory.append([a])

        if self.memory_size > 0 and len(self.memory) > self.memory_size:
          self.memory.pop(0)
          self.orderedMemory.pop(0)

    def get_batch(self, model, batch_size, gamma=0.9):
      memLen = len(self.memory)

      nb_actions = model.layers[-1].output_shape[-1]

      samples = np.array(sample(self.memory, memLen))

      input_dim = np.prod(self.orig_input_shape)
      S = samples[:, 0 : input_dim]
      a = samples[:, input_dim]
      r = samples[:, input_dim + 1]
      S_prime = samples[:, input_dim + 2 : 2 * input_dim + 2]

      r = r.repeat(nb_actions).reshape((memLen, nb_actions))

      S = S.reshape((memLen, ) + self.orig_input_shape)
      S_prime = S_prime.reshape((memLen, ) +self.orig_input_shape)

      X = np.concatenate([S, S_prime], axis=0)
      Y = model.predict(X)

      if(math.isnan(Y[0][0])):
        raise Exception("Prediction is broken :(")

      ybs_ = Y[memLen:]
      Qsa = np.max(ybs_, axis=1).repeat(nb_actions).reshape((memLen, nb_actions))

      y_bs = Y[:memLen]
      y_bs_rs = np.max(y_bs, axis=1).repeat(nb_actions).reshape((memLen, nb_actions))

      a = np.cast['int'](a)
      delta = np.zeros((memLen, nb_actions))
      deltaMinSize = 1 # int(y_bs_rs.shape[0] / len(a))

      for i in range(0, len(a)):
        deltaPiece = np.zeros((deltaMinSize, nb_actions))
        aa = np.array([a[i]])
        arange = np.arange(deltaMinSize)
        deltaPiece[arange, aa] = 1
        delta[i] = deltaPiece

      '''
      # Original algorithm:
      game_over = samples[:, 2 * input_dim + 2]
      game_over = game_over.repeat(nb_actions).reshape((memLen, nb_actions))
      r = r.reshape((memLen, nb_actions))
      r /= upTo
      rgo = r + gamma * (1 - game_over)
      targets = (1 - delta) * y_bs_rs + delta * (rgo * Qsa)
      '''

      r = r.reshape((memLen, nb_actions))

      avgPredict = (y_bs_rs + Qsa)/2 # I don't know if it has really sense
      deltaMin = 1 - delta

      targets = (deltaMin * avgPredict) + (delta * r)

      return S, targets

    @property
    def memory_size(self):
        return self._memory_size

    @memory_size.setter
    def memory_size(self, value):
        if value > 0 and value < self._memory_size:
            self.memory = self.memory[:value]
        self._memory_size = value

    def reset_memory(self):
        self.memory = []

    def  one_hot(self, seq, num_classes):
        return K.one_hot(K.reshape(K.cast(seq, "int32"), (-1, 1)), num_classes)


###
### Game parent class
###

class Game(object):

  def __init__(self):
    self.reset()

  @property
  def name(self):
    return "Game"

  @property
  def nb_actions(self):
    return 0

  def reset(self):
    pass

  def play(self, action):
    pass

  def get_state(self):
    return None

  def get_score(self):
    return 0

  def is_over(self):
    return False

  def is_won(self):
    return False

  def get_frame(self):
    return self.get_state()

  def draw(self):
    return self.get_state()

  def get_possible_actions(self):
    return range(self.nb_actions)

"""An example of implementation of Game class could be found here: https://github.com/farizrahman4u/qlearning4k/blob/master/qlearning4k/games/snake.py

# How works
The "game" we will create is based on fixed cycles, some costants and fixed variables that the machine can interpret and alter using the operations at its disposition, with the possibility to use additional variables.

The game looks like a vim editor and its input is represented by integers. The virtual screen is represented by a scrollable grid where every "pixel" is represented by an array of 3 items: **isSelected**, **class**, **value**.
- **isSelected**: 0 normally, 1 if the focus is on this element.
- **class**: The type of the value. 0 for labels, 1 for numbers.
- **value**: The ID of the label or the value of the number.

## Possible actions
- **right**: Move the cursor on the right
- **down**: Change the current pixel to the next value

## Variables and costants rappresentation
Are used two pixels for representing a store: the type and the value.
The type: in the labeling point of view is composed by two chars, representing the type of the store, if it's a decimal or a boolean (d or b), and if it's a constant or a variable (# or \$).

The value it's the position of the store in the stack.

- For example a decimal constant at position 2 is written: `d# 2`
- A boolean variable at position 1 is written: `b$ 1`

The total store type are finally 4:
1.   `d#`
2.   `b#`
3.   `d$`
4.   `b$`

## Instruction representation
A line is used to represent an instruction. It's composed by:
`lineNumber storeValueTo operation storeArg1 storeArg2`

An example could be a sum:
`1 d$1 SUM d$0 d#2 `, which is the equivalent of `d$1 = d$0 + d#2`

During the selection of the first store is possible to select just variables or the label `IF`. In this last case the continuation of the instruction change radically: in fact after an IF there is just the store boolean.

Totally, a line is at a maximum long 8 pixels.

## IF and END statements
`IF` and `END` statements are unique instructions different than normal operations lines.
In fact they take just zero or one argument, meaning the boolean store which conditions the behavior of the `IF`. During the writing of the `IF` the next instructions enter in a new context. For exiting from current context is necessary to use the `exit` action, which set the next line to `END` instruction. The `END` instruction could be also used for ending the entire script.

## Loops
For the moment loops are not supported, but they could be necessary for more precision in the best result possible. Anyway, it's a complication which must be handled delicately.

## The cycle
The cycle is composed by these variable (this is pseudo-code)

```
decimal #zero = 0
decimal #one = 1

bool #false = false
bool #true = true

decimal #step = 2 // the cycle starts from 2
decimal #i // #step - 1
decimal #numPrimes = 0 // the current number of found primes
decimal #lastPrime = 0 // the difference between the current step and the last found prime

decimal #primeProb = 0 // the current probability of a prime in the stack
decimal #notPrimeProb = 1 // 1 - #primeProb

decimal #predictedNotPrimeProb = 0 // the predicted probability of a not prime
decimal #predictedPrimeProb // 1 - #predictedNotPrimeProb

// Calculate #predictedNotPrimeProb if it's a prime
decimal #ifPrimePredictNotPrimeProb
decimal #ifPrimePredictPrimeProb

decimal #quanto // 1 / step

bool $isPrime = false

while(#step < upTo){

  #i = step - 1  
  #quanto = 1 / #step

  #ifPrimePredictNotPrimeProb = #predictedNotPrimeProb
  if (#ifPrimePredictNotPrimeProb == 0){
      #ifPrimePredictNotPrimeProb = #quanto
  }
  else {
      decimal primeStamp = #quanto
      primeStamp *= #predictedPrimeProb
      #ifPrimePredictNotPrimeProb += primeStamp
  }    

  decimal #ifPrimePredictPrimeProb = 1 - #ifPrimePredictNotPrimeProb

  ///////////////////////////////////////
  /////////// GAME CONTENT //////////////
  ///////////////////////////////////////

  if($isPrime){
    #numPrimes += 1
    #lastPrime = 0

    #predictedNotPrimeProb = #ifPrimePredictNotPrimeProb
    #predictedPrimeProb = #ifPrimePredictPrimeProb
  }

  #primeProb = #numPrimes / #i
  #notPrimeProb = 1 - #primeProb

  #lastPrime += 1
  #step += 1
}

```

### Additional stores
These are stores which can be added later.



```
decimal #probNextPrime
decimal #probNextNotPrime
decimal #predictNextPrime
decimal #predictNextNotPrime

decimal #nextPrime = 0
decimal #nextNotPrime = 0

cycle {

  #probNextPrime = 1 / #primeProb
  #probNextNotPrime = 1 / (1 - #primeProb)
  #predictNextPrime = 1 / #predictedPrimeProb
  #predictNextNotPrime = 1 / #predictedNotPrimeProb

  //////// STUFF //////////

  if($isPrime){
    #nextPrime += #predictNextPrime
    #nextNotPrime -= 1
  }
  else {
    #nextNotPrime += #predictNextNotPrime
    #nextPrime -= 1
  }
}
```

## Labels
"""

labels = []

storeTypes = []
storeTypes.append('d#')
storeTypes.append('b#')
storeTypes.append('d$')
storeTypes.append('b$')
labels.extend(storeTypes)

alternativeStartInstruction = ['IF', 'END']
labels.extend(alternativeStartInstruction)

"""## Operations

Divided by the type returned

### Neutral
- `ASSIGN`: store's value assigned to another store
- `DEFAULT`: if the assign variable doesn't exists, set the argument value

They both take just 1 argument of the same type.

### Decimal:
- `ADD`: addition
- `SUB`: subtract
- `MUL`: multiply
- `DIV`: divide

### Boolean:
- `NOT`: invert bool value [boolean]
- `CMP`: compare
- `GT`: great than [decimal]
- `GET`: great or equal than [decimal]

#### Removed:
- `LT`: less than [decimal]
- `LET`: less or equal than [decimal]

The reason of `LT` and `LET` removement it's that the same result could be obtained with an `GT` and `GET` inverting the arguments order.

"""

neutralOps = ['ASSIGN', 'DEFAULT']
labels.extend(neutralOps)

decimalOps = []
decimalOps.append('ADD')
decimalOps.append('SUB')
decimalOps.append('MUL')
decimalOps.append('DIV')
labels.extend(decimalOps)

boolOps = []
boolOps.append('NOT')
boolOps.append('OR')
boolOps.append('CMP')
boolOps.append('GT')
boolOps.append('GET')
#boolOps.append('LT')
#boolOps.append('LET')
labels.extend(boolOps)

boolOps_bool = ['NOT', 'OR']
boolOps_decimal = ['GT', 'GET', 'LT', 'LET']

oneArgOps = ['NOT']

"""# Default costants and variables


"""

storesNames = {}
storesNamesAssoc = {}
stores = {}

def assocNames(names, storeType):
  storesNames[storeType] = names
  stores[storeType] = []

  for name in names:
    storesNamesAssoc[name] = storeType

boolCostNames = [
    'false',
    'true'
]

boolVarsNames = [
    #'isPrime'
]

decimalCostNames = [
    'zero',
    'one',
    'step',
    'i',
    'numPrimes',
    'lastPrime',
    'primeProb',
    'notPrimeProb',
    'predictedNotPrimeProb',
    'predictedPrimeProb',
    'ifPrimePredictNotPrimeProb',
    'ifPrimePredictPrimeProb',
    'quanto'
]

decimalVarsNames = []

engineFault = False

def resetStores():
  storesNames = {}
  storesNamesAssoc = {}
  stores = {}

  assocNames(boolCostNames, 'b#')
  assocNames(boolVarsNames, 'b$')
  assocNames(decimalCostNames, 'd#')
  assocNames(decimalVarsNames, 'd$')

resetStores()

def getNameType(name):
  if name in storesNamesAssoc:
    return storesNamesAssoc[name]
  else:
    return None

def setStore(name, value):
    isCost = name.startswith('#')
    name = name[1:]

    isBool = isinstance(value, bool)

    storeTypeSaved = getNameType(name)

    storeType = ''
    if isBool:
      storeType += 'b'
    else:
      storeType += 'd'

    if isCost:
      storeType += '#'
    else:
      storeType += '$'

    typeNames = None
    pos = -1

    if storeTypeSaved is not None:
      if storeTypeSaved != storeType:
        raise Exception("Excepted store of type " + storeTypeSaved + ", received " + storeType)

      typeNames = storesNames[storeType]
      pos = typeNames.index(name)

    else:
      typeNames = storesNames[storeType]

      pos = len(typeNames)
      typeNames.append(name)
      storesNamesAssoc[name] = storeType

    if not isBool and not isinstance(value, myFloat):
      value = myFloat(value)

    st = stores[storeType]

    if len(st) <= pos:
      st.append(value)
    else:
      st[pos] = value

def getStore(name):
  isCost = name.startswith('#')
  isVar = name.startswith('$')

  if isCost or isVar:
    name = name[1:]

  storeTypeSaved = getNameType(name)

  if storeTypeSaved is None:
    raise Exception("Store "+name+" not found")

  typeNames = storesNames[storeTypeSaved]
  pos = typeNames.index(name)

  return stores[storeTypeSaved][pos]

def setStoreFields(fields, value):
  storeType = fields[0]
  pos = fields[1]

  reqBool = storeType.startswith('b')
  if reqBool:
      try:
          value = bool(value)
      except:
          print('neu')

  valBool = isinstance(value, bool)

  if reqBool != valBool:
    raise Exception("Different type assignation for ",storeType, " (valueIsBool:",valBool,", reqBool:",reqBool,", value:",value,")");

  if not valBool and not isinstance(value, myFloat):
    value = myFloat(value)

  st = stores[storeType]

  if len(st) <= pos:
    st.append(value)
  else:
    st[pos] = value

def getStoreFields(fields):
  if len(fields) != 2:
    print("Error: as fields I got a ", fields)

  storeType = fields[0]
  pos = fields[1]

  if not checkStoreFields(fields):
    engineFault = True
    print("Error for fields", fields, stores[storeType])
    raise Exception("Fields fault: check it")

    if storeType.startswith('d'):
        return 0
    else:
        return False

  return stores[storeType][pos]

def checkStoreFields(fields):
  storeType = fields[0]
  pos = fields[1]

  return pos < len(stores[storeType])

"""# Engine
This is the engine that interpret commands and executes the cycles.
"""

def fieldIsStore(f):
  return f in storeTypes

def instructionsToByteCode(instructions):
  res = []
  parent = []
  context = res
  end = False

  for instr in instructions:
    if end:
      break

    resInstr = []

    acc = '' # accumuling
    nextIsStore = False
    isCondition = False

    def addToResInstr(val):
      if isCondition:
        resInstr['condition'] = val
      else:
        resInstr.append(val)

    for f in range(0, len(instr)):
      field = instr[f]

      if field == '': # it depends how is done the instruction array
        break

      #print('Reading field ',field, nextIsStore)

      if f == 0: # if it's the first field of the line
        if field == 'IF':
          resInstr = {'statement': field, 'condition':[], 'context': []}
          isCondition = True
          context.append(resInstr)
          parent.append(context)
          context = resInstr['context']
          continue

        if field == 'END':
          if len(parent) == 0:
            end = True
            break

          context = parent.pop()

      if not nextIsStore: # is not store second value
        nextIsStore = fieldIsStore(field)

        if not nextIsStore:
          addToResInstr([field]) # add normally
        else:
          acc = field # accumulate store first value for next field
      else: # is store second value
        addToResInstr([acc, field])
        nextIsStore = False

    if not isCondition: # if it's a condition it's already added to context
      context.append(resInstr)

  return res

###
### Interpret bytecode
###

def interpretBytecode_condition(condition):
  #print('Condition: ', condition)
  match condition['statement']:
    case 'IF':
      if getStoreFields(condition['condition']):
        interpretBytecode(condition['context'])

    case _:
      raise Exception("Condition "+condition['statement']+" not found")

def interpretBytecode_line(line):
  lineLen = len(line)

  if lineLen == 0:
    return

  if lineLen < 3:
    cmd = line[0][0]

    if cmd == 'END':
      return #todo: Handle better the END command

  assignTo = line[0]

  operation = line[1][0]
  arg1 = getStoreFields(line[2])

  if lineLen > 3:
    arg2 = getStoreFields(line[3])

  # Here there is not control about the right type used for the operation:
  # it's assumed that Calculon automatically removed wrong types from selectionable options

  write = True
  res = None
  match operation:
    # Neutral
    case 'ASSIGN':
      res = arg1

    case 'DEFAULT':
      res = arg1
      write = not checkStoreFields(assignTo)

    # Decimal
    case 'ADD':
      res = arg1 + arg2

    case 'SUB':
      res = arg1 - arg2

    case 'MUL':
      res = arg1 * arg2

    case 'DIV':
      if arg2 == 0:
        res = 0 # wrong but temporary response
        #todo: Handle this condition blocking the game
      else:
        res = arg1 / arg2

    # Bool
    case 'NOT':
      res = not arg1

    case 'OR':
      res = arg1 or arg2

    case 'CMP':
      res = arg1 == arg2

    case 'GT':
      res = arg1 > arg2

    case 'GET':
      res = arg1 >= arg2

    case _:
      raise Exception('Operation '+ operation +' not found')

  if write:
    setStoreFields(assignTo, res)

def interpretBytecode(bytecode):
  for line in bytecode:
    isCondition = isinstance(line, dict)

    if isCondition:
      interpretBytecode_condition(line)
    else:
      interpretBytecode_line(line)

###
### Execute Cycles
###

def resetEngine():
  engineFault = False

  resetStores()

  setStore('#zero', 0)
  setStore('#one', 1)

  setStore('#false', False)
  setStore('#true', True)

  setStore('#step', 2)
  setStore('#i', 1)

  setStore('#numPrimes', 0)
  setStore('#lastPrime', 0)

  setStore('#primeProb', 0)
  setStore('#notPrimeProb', 1)

  setStore('#predictedNotPrimeProb', 0)
  setStore('#predictedPrimeProb', 1)

  setStore('#ifPrimePredictNotPrimeProb', 0)
  setStore('#ifPrimePredictPrimeProb', 0)

  setStore('#quanto', 1)

  #setStore('$isPrime', False)

resetEngine() # reset by default

def executeCycles(instructions, isPrimeVar=0):
  bytecode = instructionsToByteCode(instructions)

  resetEngine()

  # Score variables
  distributionDiff = 0
  distributionMaxDiff = 0

  # Cache stores
  step = getStore('#step')
  i = getStore('#i')
  quanto = None
  ifPrimePredictNotPrimeProb = None
  ifPrimePredictPrimeProb = None
  predictedPrimeProb = getStore('#predictedPrimeProb')
  predictedNotPrimeProb = getStore('#predictedNotPrimeProb')
  isPrime = None
  numPrimes = getStore('#numPrimes')
  lastPrime = getStore('#lastPrime')

  while(step <= upTo):
    i = step-1
    quanto = 1/step

    ifPrimePredictNotPrimeProb = getStore('#predictedNotPrimeProb')

    # Calculate if prime prediction probability
    primeStamp = quanto
    primeStamp *= predictedPrimeProb
    ifPrimePredictNotPrimeProb += primeStamp
    ifPrimePredictPrimeProb = 1 - ifPrimePredictNotPrimeProb

    setStore('#i', i)
    setStore('#quanto', quanto)
    setStore('#ifPrimePredictNotPrimeProb', ifPrimePredictNotPrimeProb)
    setStore('#ifPrimePredictPrimeProb', ifPrimePredictPrimeProb)

    ###
    ### Cycle
    ###

    interpretBytecode(bytecode)

    ###
    ### End cycle
    ###

    isPrime = getStoreFields(['b$', isPrimeVar])

    if isPrime:
      numPrimes += 1
      lastPrime = 0

      predictedNotPrimeProb = ifPrimePredictNotPrimeProb
      predictedPrimeProb = ifPrimePredictPrimeProb

    primeProb = numPrimes / i
    notPrimeProb = 1 - primeProb

    lastPrime += 1
    step += 1

    setStore('#numPrimes', numPrimes)
    setStore('#lastPrime', lastPrime)
    setStore('#predictedNotPrimeProb', predictedNotPrimeProb)
    setStore('#predictedPrimeProb', predictedPrimeProb)
    setStore('#primeProb', primeProb)
    setStore('#notPrimeProb', notPrimeProb)
    setStore('#step', step)

    # Add score
    i = int(i)
    effectiveNumPrimes = distribution[i-1]
    numPrimesDiff = numPrimes - effectiveNumPrimes

    if numPrimesDiff < 0:
      numPrimesDiff /= effectiveNumPrimes
      numPrimesDiff *= -1
      distributionDiff += numPrimesDiff

    elif numPrimesDiff > 0:
      numPrimesDiff /= i - effectiveNumPrimes
      distributionDiff += numPrimesDiff

    distributionMaxDiff += 1

  distributionDiff /= distributionMaxDiff
  return (1 - distributionDiff)

"""# The 'game'
This is the implementation of *Game* class for implementing the IDE. This 'game' is called Calculon.
"""

actions = {0:'right', 1:'down'} # down action is currently unused in the q learning model
ideWidth = 7

# Game options
drawLineNumber = False
dontAllowEndOnDepth0 = True
forceAssignToNewVar = True
allowAssign = False

if not allowAssign:
  neutralOps.remove('ASSIGN')

rewardVars = [
    #['b$', storesNames['b$'].index('isPrime'), 3],
    ['d#', storesNames['d#'].index('primeProb')],
    ['d#', storesNames['d#'].index('predictedPrimeProb')],
    ['d#', storesNames['d#'].index('lastPrime')]
]

def cloneDictOfArr(arr):
  res = {}
  for i in arr:
    res[i] = arr[i].copy()
  return res

def checkVarReward(stype, num=-1):
  reward = 0
  for var in rewardVars:
    if num >= -1:
      if stype == var[0] and num == var[1]:
        varReward = 1
        if len(var) > 2:
          varReward = var[2]
        return varReward
    else:
        if stype == var[0]:
            reward += 1
            return 1 # disable store type reward weight
  return reward


class Calculon(Game):

  def __init__(self, num_lines=100):
    self.num_lines = num_lines
    self.reset()
    self.state_changed = True

    self.maxScore = 0
    self.maxScoreLen = 0

    self.ideWidth = ideWidth
    if drawLineNumber:
      self.ideWidth += 1

  @property
  def name(self):
    return "Calculon"
  @property
  def nb_actions(self):
    return 2

  def play(self, action):
    if action not in range(self.nb_actions):
      print('Called wrong action: ', action)
      self.currentReward = -2 # punish the agent ^-^
    else:
        self.currentAction = action
        self.currentReward = 1 # currently unused

        try:
          match action:
            case 0: # right
              self.goRight()

            case 1: # down
              self.goDown()

        except Exception as error:
          print('instruction: ', self.instructions[self.focus_y])
          raise Exception('Error: ', error)

    self.lineReward += self.currentReward
    return self.currentReward

  def extractWinnerVarInstructions(self):
    wv = self.lastBoolVarAssign

    instructionsCp = self.instructions.copy()

    # Compensate missing ends
    missingEnds = 0
    for instr in instructionsCp:
      if len(instr) > 0:
        if instr[0] == 'IF':
          missingEnds += 1
        elif instr[0] == 'END':
          missingEnds -= 1

    if missingEnds > 0:
      for i in range(0, missingEnds):
        instructionsCp.append(['END'])

    # Find first important instruction
    startFrom = len(instructionsCp)
    while startFrom > 0:
      startFrom -= 1
      instr = instructionsCp[startFrom]

      if len(instr) == 0:
        continue

      if instr[0] == 'b$' and instr[1] == wv:
        break

    usedVars = {'b$': [wv], 'd$': []}
    assigns = {'d$':[], 'b$':[]}
    instructions = []

    def getAssignIndex(var):
      nonlocal assigns
      ass = assigns[var[0]]
      ivar = -1
      for i in range(0, len(ass)):
        if ass[i] == var[1]:
          ivar = i
          break
      return ivar

    def checkAssign(var):
      nonlocal assigns
      ass = assigns[var[0]]
      ivar = getAssignIndex(var)

      if ivar >= 0:
        ass.pop(ivar)

      ass.insert(0, var[1])

    self.workingLines = []
    i = startFrom

    previousStackWasRelevant = False

    def stack():
      nonlocal usedVars
      nonlocal i
      nonlocal instructions
      nonlocal previousStackWasRelevant

      stackInstructions = []
      stackWorkingLines = []
      stackIsRelevant = False

      stackLen = 0
      while i >= 0:
        stackLen += 1
        instr = instructionsCp[i]
        i -= 1

        assign = None
        vars = []

        relevant = False
        endOfStack = False
        isAssign = True
        isVar = False
        lastVarType = ''
        isCondition = False
        for field in instr:
          if isVar:
            vars.append([lastVarType, field])
            if isAssign:
              assign = [lastVarType, field]
            isVar = False

          elif str(field).endswith('$'):
            isVar = True
            lastVarType = field
          else:
            if isAssign:
              # Check stack
              if field == 'END':
                line = i+1
                if line < len(self.instructions):
                  stackWorkingLines.append(line)
                    
                stack()
              elif field == 'IF':
                relevant = stackIsRelevant
                stackInstructions.append(['END'])
                endOfStack = True
                isCondition = True

              isAssign = False

        # Check if it's a relevant instruction
        if not isCondition:
          for var in vars:
            if var[1] in usedVars[var[0]]:
              relevant = True
              break

        if relevant:
          stackIsRelevant = True

          for var in vars:
            if var[1] not in usedVars[var[0]]:
              usedVars[var[0]].append(var[1])

          if assign != None:
            checkAssign(assign)

          stackWorkingLines.append(i+1)
          stackInstructions.insert(0, instr.copy())
          stackIsRelevant = True

        if endOfStack:
          break

      if stackIsRelevant:
        nonlocal instructions
        instructions = stackInstructions + instructions
        self.workingLines = self.workingLines + stackWorkingLines

      return stackIsRelevant

    while i >= 0:
      stack()

    # Reorder assigns
    for i in range(0, len(instructions)):
      instr = instructions[i]

      isVar = False
      lastVarType = ''
      for f in range(0, len(instr)):
        field = instr[f]
        if isVar:
          newIndex = getAssignIndex([lastVarType, field])
          if newIndex == -1: # just for debug purposes
            print("newIndex error")
          instr[f] = newIndex
          isVar = False
        elif str(field).endswith('$'):
          isVar = True
          lastVarType = field

    self.curWinnerInstructions = instructions
    self.curWinnerInstructions_winner = getAssignIndex(['b$', wv])

    return instructions # finally!

  def newLine(self):
    if self.focus_y >= 0:
      # Calculate current score
      self.inNewLine = True
      self.lastLineLen = len(self.curLine)

      self.usedStores = self.lineUsedStores

    print('Written line: ', self.curLine, '   ', self.focus_y,'/',self.num_lines)

    if self.curLine_isCondition:
      self.newStack()

    self.resetCurLine()

    self.focus_y += 1

    if self.focus_y >= self.num_lines:
      self.checkGameEnd()

  def resetCurLine(self, removeLine=False):
    if removeLine:
      self.instructions.pop(len(self.instructions)-1)
      self.lastBoolVarAssign = None

    self.curLine = []
    self.instructions.append(self.curLine)

    self.endOfLine = 7

    self.focus_x = 0

    self.curLine_previousIsStoreTypes = False
    self.curLine_isOperation = False
    self.curLine_isCondition = False
    self.curLine_isAssign = False
    self.curLine_argNum = 0

    self.totalReward += self.lineReward
    self.lineReward = 0

    self.forkUsedStores()

  def forkUsedStores(self):
    self.lineUsedStores = self.usedStores.copy()

  def loadOptions_variables(self):
    for t in range(2, len(storeTypes)): # Add just variables
      self.options.append(storeTypes[t])

  def loadOptions_decimal(self):
    for t in range(0, len(storeTypes)): # Add just variables
      if t % 2 == 0:
        self.options.append(storeTypes[t])

  def loadOptions_bool(self):
    for t in range(0, len(storeTypes)): # Add just variables
      if t % 2 == 1:
        self.options.append(storeTypes[t])

  def checkGameEnd(self):
    if self.current_score == 1:
      self.game_won = True
    else:
      self.game_won = False

    self.game_over = True

  def getNumStores(self, stype, excepted=-1):
    res = self.usedStores[stype]

    if res == excepted:
      self.lineUsedStores[stype] += 1

    return res

  def loadOptions_Condition(self):
    stores = []

    numVars = self.getNumStores('b$')
    for s in range(0, numVars):
      if s not in self.assignStores['b$']:
        stores.append(s)

    return stores

  def countConditionOptions(self):
    return len(self.loadOptions_Condition())

  def loadOptions(self):
    self.options = []
    self.selOption = 0

    hasStore = False
    self.curLine_isAssign = self.focus_x == 1 and self.curLine_previousIsStoreTypes

    # Load available stores
    if self.curLine_previousIsStoreTypes:
      if self.curLine_isAssign:

        if forceAssignToNewVar:
          if self.depth > 0:
            for i in self.assignStores[self.curLine_storeType]:
              self.options.append(i)
        else:
          for i in self.assignStores[self.curLine_storeType]:
            self.options.append(i)

        if self.depth == 0:
          self.options.append(self.getNumStores(self.curLine_storeType))

      elif self.curLine_isCondition:
        self.options = self.loadOptions_Condition()
      else:
        for i in range(0, self.usedStores[self.curLine_storeType]):
          self.options.append(i)

        if self.curLine_argNum == 2:
          if self.curLine_2argSt == self.curLine_storeType:
            self.options.remove(self.curLine_2argNum)

    else:
      match self.focus_x:
        case 0:
          self.loadOptions_variables()
          self.options.extend(alternativeStartInstruction)
          hasStore = True

        case 1: # In case of condition
          if self.curLine_isCondition:
            self.options = ['b$']

        case 2: # In case of operation
          self.options.extend(neutralOps)

          # Handle DEFAULT operation
          if self.depth > 0:
            self.options.remove('DEFAULT')
          elif self.getNumStores(self.curLine_assignType) != self.curLine_assignNum:
            self.options.remove('DEFAULT')

          if self.curLine_assignIsBool:
            self.options.extend(boolOps)
          else:
            self.options.extend(decimalOps)

          self.curLine_isOperation = True
          hasStore = True

        case 3:
          match self.curLine_opType:
            case 'n':
              if self.curLine_assignIsBool:
                self.loadOptions_bool()
              else:
                self.loadOptions_decimal()

            case 'b':
              if self.curLine_opReq == 'b':
                  self.loadOptions_bool()
              elif self.curLine_opReq == 'd':
                  self.loadOptions_decimal()
              else:
                  self.options.extend(storeTypes)

            case 'd':
              self.loadOptions_decimal()

            case _:
              print('Wrong curLine_opType: ', self.curLine_opType)

          if not self.curLine_isOperation:
            raise Exception('This line is not an operation...')

          hasStore = True

        case 5:
          if self.curLine_argsAreBool:
            self.loadOptions_bool()
          else:
            self.loadOptions_decimal()

            hasStore = True

      if hasStore:
        remove = []
        for opt in self.options:
          if opt in stores:
            if self.focus_x == 0:
              if self.depth > 0 and len(self.assignStores[opt]) == 0:
                remove.append(opt)
            else:
              if self.usedStores[opt] == 0:
                remove.append(opt)

        for rem in remove:
          self.options.remove(rem)

    if dontAllowEndOnDepth0 and self.depth <= 0: # and not self.maxScoreSurpass:
      if 'END' in self.options:
        self.options.remove('END')

    if 'IF' in self.options and (self.countConditionOptions() == 0):
      self.options.remove('IF')

    #todo: Delete these lines (just for debug purposes)
    #if self.focus_x > 1:
    #  self.options = []

    if len(self.options) == 0:
      print("All options excluded...")
      print("curLine: ", self.curLine)

      # Reset curLine
      self.resetCurLine(True)
      self.loadOptions()

    random.shuffle(self.options)

  def newStack(self):
    self.assignStoresStack.append(self.assignStores)
    self.initAssignStores()

  def initAssignStores(self):
    if self.depth == 0:
      self.assignStores = {'d$':[], 'b$':[]}

      self.setAsUsedStoreType('d$')
      self.setAsUsedStoreType('b$')
    else:
      self.assignStores = self.assignStores.copy()

  def setAsUsedStoreType(self, stype):
    for i in range(0, self.getNumStores(stype)):
      self.varIsUsed(stype, i)

  def varIsAssigned(self, stype, var):
    if stype == 'b$':
      self.lastBoolVarAssign = var

    if stype in self.assignStores and var in self.assignStores[stype]:
      self.assignStores[stype].remove(var)

  def varIsUsed(self, stype, var):
    if stype in self.assignStores and var not in self.assignStores[stype]:
      self.assignStores[stype].append(var)

  def oldStack(self):
    self.assignStores = self.assignStoresStack.pop()

  @property
  def optionsLen(self):
    return len(self.options)

  def saveOption(self):
    if self.selOption == -1:
      return

    if self.selOption >= len(self.options):
      print('Error on selOption: ', self.focus_x, self.focus_y)
      raise Exception('selOption out of bounds: ', self.selOption, ' in ', self.options);

    opt = self.options[self.selOption]
    self.curLine.append(opt)

    if opt == 'END':
      self.endOfLine = 0

      self.depth -= 1
      if(self.depth < 0):
        self.currentReward = -1
        self.checkGameEnd()
      else:
        self.oldStack()

      return

    if self.curLine_previousIsStoreTypes:
      self.getNumStores(self.curLine_storeType, opt)
      self.currentReward += checkVarReward(self.curLine_storeType, opt)

      if self.curLine_argNum == 1:
        self.curLine_2argSt = self.curLine_storeType
        self.curLine_2argNum = opt

      self.curLine_argNum += 1

      if self.curLine_isAssign: # is assignation
        self.varIsAssigned(self.curLine_storeType ,opt)
        self.curLine_assignNum = opt
        self.curLine_isAssign = False
      else:
        self.varIsUsed(self.curLine_storeType, opt)

      self.curLine_previousIsStoreTypes = False
      return

    self.curLine_previousIsStoreTypes = opt in storeTypes

    if self.curLine_previousIsStoreTypes:
        self.currentReward += checkVarReward(opt)
        self.curLine_storeType = opt
        self.curLine_storeIsBool = opt.startswith('b')

    match self.focus_x:
      case 0:
        if self.curLine_previousIsStoreTypes:
          self.curLine_assignIsBool = self.curLine_storeIsBool
          self.curLine_assignType = self.curLine_storeType
        else:
          # In case of condition
          self.curLine_isCondition = True
          self.endOfLine = 2
          self.depth += 1

      case 2:
        if not self.curLine_previousIsStoreTypes:
          self.curLine_opReq = 'NaN'

          if opt in neutralOps:
            self.curLine_opType = 'n'
          elif self.curLine_assignIsBool:
            self.curLine_opType = 'b'

            if opt in boolOps_bool:
                self.curLine_opReq = 'b'

            if opt in boolOps_decimal:
                self.curLine_opReq = 'd'

          else:
            self.curLine_opType = 'd'

          if opt in oneArgOps:
            self.endOfLine = 2

          if opt in neutralOps:
            self.endOfLine = 2

      case 3:
        self.curLine_argsAreBool = self.curLine_storeIsBool

  def goRight(self):
    self.inNewLine = False

    self.saveOption()

    self.focus_x += 1
    self.endOfLine -= 1

    self.totalReward *= 0.9

    if self.endOfLine < 0 or self.focus_x >= 7:
      self.newLine()

    self.loadOptions()

  def goDown(self, selOption=-1):

    if selOption == -1:
      self.selOption += 1
    else:
      self.selOption = selOption

    if self.selOption >= len(self.options):
      self.currentReward = -1
      self.selOption -= 1
    else:
      opt = self.options[self.selOption]
      if self.curLine_previousIsStoreTypes:
        self.currentReward += checkVarReward(self.curLine_storeType, opt)
      else:
        if opt in storeTypes:
          self.currentReward += checkVarReward(opt)

  def countInstructionsElements(self, instructions=None):
    if instructions == None:
      instructions = self.instructions

    tot = 0
    for instr in instructions:
      tot += len(instr)

    return tot

  def get_state(self, until=0, instructions=None):
    if instructions == None:
      instructions = self.instructions

    startFrom = 0
    if drawLineNumber:
      startFrom = 1

    totElements = self.countInstructionsElements(instructions)

    if until == 0:
      until = totElements
    elif until < 0:
      until += totElements

    # Draw the current view
    canvas = []

    elNumber = 0
    for y in range(0, self.num_lines):
      elNumber += 1
      line = []

      instruction = []
      if y < len(instructions):
        instruction = instructions[y]

      if drawLineNumber:
        line.append([0, 1, y])

      for x in range(startFrom, self.ideWidth):
        xx = x - startFrom
        pixel = [0, 0, 0]

        def setPixelVal(val):
          isNum = isinstance(val, int)

          if isNum:
            pixel[1] = 1
          else:
            val = labels.index(val)

          pixel[2] = val

        if elNumber == until or (until == totElements and y == self.focus_y and xx == self.focus_x):
          pixel[0] = 1
          setPixelVal(self.options[self.selOption])
        elif elNumber < until and xx < len(instruction):
          setPixelVal(instruction[xx])

        line.append(pixel)

      canvas.append(line)

    return np.array(canvas, dtype=np.uint)

  def get_score(self):
    # Execute instructions
    self.current_score = 0

    if self.lastBoolVarAssign != self.lastCalculatedBoolVar and self.lastBoolVarAssign != None:
      self.extractWinnerVarInstructions()

      self.current_score = executeCycles(self.curWinnerInstructions, self.curWinnerInstructions_winner)
      self.lastCalculatedBoolVar = self.lastBoolVarAssign
      self.lastCalculatedScoreLine = len(self.instructions)

    print("Score: ", self.current_score)

    if self.current_score == 1:
      self.checkGameEnd()

    return self.current_score

  def reset(self):
    self.instructions = []
    self.curLine = ['WELCOME :)']

    self.focus_x = 0
    self.focus_y = -1

    self.game_over = False
    self.game_won = False
    self.maxScoreSurpass = False

    self.depth = 0

    self.current_score = 0

    self.selOption = -1
    self.endOfLine = 0

    self.currentReward = 0 # currently unused
    self.lineReward = 0
    self.totalReward = 0

    resetEngine()
    self.usedStores = {'d#': 0, 'b#':0, 'd$':0, 'b$':0}
    for t in self.usedStores:
      self.usedStores[t] = len(stores[t])
    self.forkUsedStores()

    self.assignStoresStack = []
    self.initAssignStores()

    self.curLine_isCondition = False

    # Init first line
    self.currentAction = -1
    self.goRight()

    self.lastBoolVarAssign = None
    self.lastCalculatedBoolVar = None
    self.lastCalculatedScoreLine = 0

    print('Reset')

  def is_over(self):
    return self.game_over

  def is_won(self):
    return self.game_won

  ### Commands
  def right(self):
    self.play(0)

"""# Execute"""

### Execution

actions = 1
grid_size = 150
game = Calculon(grid_size)
input_shape = (grid_size, game.ideWidth, 3)

"""## Models

### DenseNet
"""

def getModelDenseNet():

  activation = 'gelu'

  def dense_block(x, growth_rate, num_layers):
      x_in = x  # Input to the dense block
      for _ in range(num_layers):
          # Bottleneck layer
          x = BatchNormalization()(x)
          x = Activation(activation)(x)
          x = Conv2D(growth_rate, kernel_size=(1, 1), padding='same')(x)

          # Composite function
          x = BatchNormalization()(x)
          x = Activation(activation)(x)
          x = Conv2D(growth_rate, kernel_size=(3, 3), padding='same')(x)

          # Concatenate with previous block
          x = Concatenate()([x, x_in])

      return x

  def transition_block(x, compression_factor):
      num_filters = int(x.shape[-1] * compression_factor)

      x = BatchNormalization()(x)
      x = Activation(activation)(x)
      x = Conv2D(num_filters, kernel_size=(1, 1), padding='same')(x)
      x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)

      return x

  def DenseNet(input_shape, num_blocks=4, num_layers_per_block=4, growth_rate=32, compression_factor=0.5, num_classes=10):
      inputs = Input(shape=input_shape)

      # Initial Convolutional layer
      x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs)
      x = BatchNormalization()(x)
      x = Activation(activation)(x)
      x = AveragePooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)

      # Dense blocks and transition blocks
      x_in = x
      for i in range(num_blocks):
          x = dense_block(x, growth_rate, num_layers_per_block)
          x_in = transition_block(x, compression_factor)

      # Final blocks
      x = dense_block(x, growth_rate, num_layers_per_block)
      x = BatchNormalization()(x)
      x = Activation(activation)(x)
      x = GlobalAveragePooling2D()(x)

      # Dense layers
      x = Dense(256, activation=activation)(x)
      x = Dense(128, activation=activation)(x)

      # Output layer
      x = Dense(num_classes, activation='linear')(x) # activation='softmax' => sigmoid

      model = Model(inputs, x)
      return model

  model = DenseNet(input_shape=input_shape, num_blocks=3, num_layers_per_block=3, growth_rate=256, compression_factor=0.5, num_classes=actions)
  model.compile(optimizer="adam", loss="mean_absolute_error")
  return model

"""### LSTM"""

def getModelLSTM():
  activation = 'gelu'
  lstm_units = 256
  num_lstm_layers = 4

  inputs = Input(shape=input_shape)
  timeSeries = TimeDistributed(LSTM(units=lstm_units, activation=activation), input_shape=input_shape)(inputs)

  # Build a dense block with LSTM layers
  lstm_layers = []
  prev_layer = timeSeries

  for _ in range(num_lstm_layers):
      lstm_layer = LSTM(units=lstm_units, return_sequences=True, activation=activation)(prev_layer)
      lstm_layers.append(lstm_layer)
      prev_layer = Concatenate()([prev_layer, lstm_layer])

  # Dense layers
  prev_layer = Dense(128, activation=activation)(prev_layer)
  prev_layer = Dense(64, activation=activation)(prev_layer)

  # Flatten
  prev_layer = Flatten()(prev_layer)

  # Final output layer
  output = Dense(actions, activation='linear', bias_initializer=tf.keras.initializers.Constant(0.0))(prev_layer)

  # Create the model
  model = Model(inputs=inputs, outputs=output)

  # Compile the model with appropriate loss, optimizer, and metrics
  model.compile(loss='mean_absolute_error', optimizer='adam') #, metrics=['accuracy']
  return model

"""## Run"""

model = getModelLSTM()

agent = Agent(model)
agent.train(game)
agent.play(game)

"""# Temporary snippets

## How to correlate to the model hidden information
This is a ChatGPT snippet:
Yes, it is possible to pass additional hidden information, represented as floats, to a Q-learning model alongside the game state represented by an integer matrix. One common approach to handle this situation is to use multiple inputs in a Keras model.

In Keras, you can create a model with multiple input layers, each handling a different type of input data. You can then combine these input layers using different types of layers (e.g., Dense, LSTM, etc.) to build a more complex model that can handle both the game state and the hidden information.

Here's a general outline of how to create a Keras model with multiple inputs:

```python
from keras.models import Model
from keras.layers import Input, Dense, concatenate

# Assuming game state is represented as an integer matrix of shape (game_rows, game_cols)
game_input = Input(shape=(game_rows, game_cols), name='game_input')

# Assuming hidden information is represented as a float vector of shape (hidden_dim,)
hidden_info_input = Input(shape=(hidden_dim,), name='hidden_info_input')

# Add layers to process the game state and hidden information
# Example: flatten the game input and add some Dense layers for game processing
game_processed = Flatten()(game_input)
game_processed = Dense(64, activation='relu')(game_processed)

# Example: add some Dense layers for hidden information processing
hidden_info_processed = Dense(32, activation='relu')(hidden_info_input)

# Combine the processed game state and hidden information using concatenate
combined = concatenate([game_processed, hidden_info_processed])

# Add more layers as needed for the Q-learning model
# Example: Dense output layer for Q-values
q_values = Dense(num_actions, activation='linear')(combined)

# Create the model with the specified inputs and outputs
model = Model(inputs=[game_input, hidden_info_input], outputs=q_values)

# Compile the model and define the loss and optimizer as needed
model.compile(optimizer='adam', loss='mse')

# Train the model using appropriate data for both inputs
# Example: game_data and hidden_info_data are the training data for game state and hidden information, respectively
model.fit([game_data, hidden_info_data], q_values_data, epochs=...)
```

In this example, we create two input layers, one for the game state and the other for the hidden information. We process each input using different layers (Dense in this case), and then concatenate the processed outputs. Finally, we continue with more layers and an output layer to produce the Q-values.

When training the model, you will need to provide appropriate training data for both the game state and hidden information inputs, along with the corresponding target Q-values.

Remember to preprocess your data appropriately before feeding it into the model. The specific architecture and hyperparameters will depend on the complexity of your game and the nature of the hidden information.

## Inspirations

### BigFloat
Exists a library in Python able to create floating point variable with dynamic precision: https://pypi.org/project/bigfloat/
"""